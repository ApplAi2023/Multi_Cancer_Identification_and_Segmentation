# -*- coding: utf-8 -*-
"""TestScript.py.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VVA29hQw0UMgmrv1LR86QzkiNT6VJ6Ly
"""

#!pip install natsort

import cv2
import os
import pandas as pd
import sklearn
import keras
from sklearn.preprocessing import OneHotEncoder
import random
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB3
from keras import applications
from keras import callbacks
from keras.models import Sequential
from keras.layers import Dense, MaxPool2D
from keras.optimizers import Adam
import numpy as np
from natsort import natsorted
from efficientnet.tfkeras import EfficientNetB2

import ipyplot

#from keras.layers.normalization import BatchNormalization
from keras.layers import *
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras.applications.resnet50 import ResNet50
from PIL import Image, ImageEnhance

from tensorflow.keras.applications.inception_v3 import InceptionV3
from keras.applications.inception_v3 import preprocess_input
from keras.applications.inception_v3 import decode_predictions
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
# from tensorflow.keras.layers import Dense, GlobalAveragePooling2

import sys
import random
import warnings #
import pandas as pd
from itertools import chain
from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.morphology import label
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dropout, Lambda
from tensorflow.keras.layers import Conv2D, Conv2DTranspose
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import concatenate
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import backend as K
import tensorflow as tfD

def binarize_mask(mask):

  ret,thresh1 = cv2.threshold(mask,127,1,cv2.THRESH_BINARY)
  return thresh1
from sklearn.utils import shuffle
IMG_SIZE=224




import gradio as gr
import base64


def predict(input ):
    imgarr = cv2.cvtColor(input, cv2.COLOR_BGR2RGB)
    imgarr = cv2.resize(imgarr, (IMG_SIZE, IMG_SIZE))
    imgarr2=imgarr
    imgarr = imgarr.reshape(1, imgarr.shape[0], imgarr.shape[1], imgarr.shape[2])

    def dice_coef(y_true, y_pred, smooth=1):
        y_true_f = K.flatten(y_true)
        y_pred_f = K.flatten(y_pred)
        intersection = K.sum(y_true_f * y_pred_f)
        return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

    model1 = load_model(r'Brain_breast.h5')
    Stage1predctions = model1.predict(imgarr)
    chatbot22 = Stage1predctions >= 0.5
    if(chatbot22):
        A1= "Breast"
        model2Breast = load_model('Breast_class.h5')
        Stage2Breastpredctions = model2Breast.predict(imgarr)
        Stage2Breastpredctions = np.argmax(Stage2Breastpredctions, axis=1)
        if Stage2Breastpredctions==1:
            A2="Benign"
        elif  Stage2Breastpredctions==2:
            A2 = "Malignant"
        else:
            #print('normal')

            A2="Normal"
            #print('normal')
            output_ = np.ones((IMG_SIZE, IMG_SIZE))
            #print('normal')
            return A1, A2, output_

        if (Stage2Breastpredctions==1 or Stage2Breastpredctions==2):
           S2Breast = imgarr
           #print(S2Breast.shape)

           model4 = load_model('Breast_seg.h5', custom_objects={'dice_coef': dice_coef})
           # print(S2Brain.shape)
           output_ = model4.predict(S2Breast)
           #print('......', output_.shape)
           output_ = output_ * 255
           # output_ = output_.reshape((IMG_SIZE,IMG_SIZE,1))
           #print(np.max(output_))
           #print(np.min(output_))
           #output_=binarize_mask(output_*255)
           #print(np.max(output_))
           #print(np.min(output_))
           #output_ = (output_ < 150) * output_
           output_ = np.int_(output_)
           output_=np.where(output_>125,255,0)
           #print(np.max(output_))
           #print(np.min(output_))
           #print(output_.shape)
           # output_=cv2.resize(output_, (IMG_SIZE, IMG_SIZE),1)
           output_ = np.squeeze(output_)
           #print('.............', output_.shape)



    else:
        A1= "Brain"
        model2Brain = load_model('Brain_class.h5')
        Stage2Brainpredctions = model2Brain.predict(imgarr)
        Stage2Brainpredctions = Stage2Brainpredctions >= 0.5
        if Stage2Brainpredctions :
            A2="Tumor"
            #S2Brain = np.array(S2Brain)
            S2Brain = imgarr / 255
            #print(S2Brain.shape)

            model3 = load_model('Brain_seg.h5', custom_objects={'dice_coef': dice_coef})
            #print(S2Brain.shape)
            output_ = model3.predict(S2Brain)
            #print('......',output_.shape)

            #output_ = output_.reshape((IMG_SIZE,IMG_SIZE,1))
            #print(np.max(output_))
            #print(np.min(output_))
            #output_ = binarize_mask(output_*255)
            output_ = (output_ < 150) * output_
            output_=np.int_(output_*255)
            #print(np.max(output_))
            #print(np.min(output_))
            #print(output_.shape)
            #output_=cv2.resize(output_, (IMG_SIZE, IMG_SIZE),1)
            output_=np.squeeze(output_)
            #print('.............',output_.shape)



        else:
            A2="No Tumor"
            output_ = np.ones((IMG_SIZE, IMG_SIZE))

            return A1, A2, output_

        # output = openai_chat(input)
    #history.append(chatbot)

    return A1,A2,output_


add_image = "body {background-image: 'ApplAiOnly_Logo.png';}"
# with gr.Blocks(css=".gradio-container {background-image: url('file=clouds.jpg')}") as demo:
# css=".gradio-container {background-image: url('file=ApplAiOnly_Logo.png')}"
interface = gr.Interface(fn=predict, title="Multi Cancer Identification and Segmentation"
                         ,examples=['y15.jpg','malignant (1).png','normal (12).png','benign (28).png','y44.jpg'],
                         inputs="image",
                         outputs=["text","text","image"])
# Customize the CSS to add a logo

interface.launch()


